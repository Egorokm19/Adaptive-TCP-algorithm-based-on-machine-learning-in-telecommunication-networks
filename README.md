# Adaptive-TCP-algorithm-based-on-machine-learning-in-telecommunication-networks
On the Internet, many devices use the TCP protocol for reliable data transfer. The main problems with network transmission are window size overload and packet loss. In TCP the sender considers network loss as the loss of packets in a transmission queue caused by network congestion. The results in poor efficiency and throughput. TCP congestion control is the problem of determining the correct size of the congestion window, which is the number of packets that the sender can send without receiving confirmation of the delivered packet. On the one hand, if the window size is too small, then the sender will not make full use of the available bandwidth. On the other hand, if the window size is too large, the packets will queue at the routers, which will increase the transit time of each packet and possibly for packet loss.
TCP is a protocol for the reliable transmission of information between computers over the Internet [1].
Network congestion is the one of the main problems in computer networks due to the limitation of the speed of information transmission over physical channels, such as Ethernet cables or cellular channels.
When an overload occurs, the queue in the channel starts to fill up, and the packets are dropped.
Packet loss is the main criterion for network congestion.
Another consequence of filling the queues is that if packets spend more time in the queue before they get into the channel, then this causes a delay in the network.

The whole project consists of several files and is described in TCP Congestion Control queue.ipynb, TCP CongestionControl.ipynb, Reinforcemen_ML_TCP.ipynb.
